# vLLM CPU Service Dockerfile
# According to official docs: https://docs.vllm.ai/en/stable/getting_started/installation/cpu.html
# 
# Option 1: Use locally built vLLM CPU image (recommended, if already built)
FROM vllm-cpu-env:latest

# Option 2: Build from source (if local image unavailable, uncomment below and comment out above FROM)
# FROM python:3.11-slim
# ARG BUILD_PROXY
# RUN apt-get update && apt-get install -y --no-install-recommends \
#     gcc g++ libnuma-dev python3-dev git cmake build-essential \
#     && rm -rf /var/lib/apt/lists/*
# WORKDIR /app
# RUN git clone https://github.com/vllm-project/vllm.git vllm_source && \
#     cd vllm_source && \
#     pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu && \
#     pip install --no-cache-dir -r requirements/cpu-build.txt && \
#     pip install --no-cache-dir -r requirements/cpu.txt && \
#     VLLM_TARGET_DEVICE=cpu pip install . --no-build-isolation && \
#     cd .. && rm -rf vllm_source

# Set working directory
WORKDIR /app

# Copy and run necessary patch scripts (only fix CPU cache ops issues)
# 1. Fix _custom_ops: add error handling for reshape_and_cache
COPY patch_custom_ops.py /app/patch_custom_ops.py
RUN python3 /app/patch_custom_ops.py && rm /app/patch_custom_ops.py

# 2. Fix CPU attention: add error handling for reshape_and_cache
COPY patch_cpu_attn.py /app/patch_cpu_attn.py
RUN python3 /app/patch_cpu_attn.py && rm /app/patch_cpu_attn.py

# 3. Fix CPU attention: add error handling for paged_attention_v1
COPY patch_paged_attention.py /app/patch_paged_attention.py
RUN python3 /app/patch_paged_attention.py && rm /app/patch_paged_attention.py

# Create model directory
RUN mkdir -p /app/models

# Copy startup script
COPY start_vllm_server.sh /app/start_vllm_server.sh
RUN chmod +x /app/start_vllm_server.sh

# Expose port
EXPOSE 8001

# Default command: start bash shell to keep container running, convenient for manual container debugging
# After entering container, can manually copy and execute startup script, or run commands directly
CMD ["/bin/bash"]
